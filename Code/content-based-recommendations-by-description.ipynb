{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be21406",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:46.289246Z",
     "iopub.status.busy": "2022-10-21T10:13:46.288778Z",
     "iopub.status.idle": "2022-10-21T10:13:46.307434Z",
     "shell.execute_reply": "2022-10-21T10:13:46.306170Z"
    },
    "papermill": {
     "duration": 0.031364,
     "end_time": "2022-10-21T10:13:46.310764",
     "exception": false,
     "start_time": "2022-10-21T10:13:46.279400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Documents\\Python Programming\\Book recommendations\\Data\\Processed\\Books_valid_ISBN_known_year_no_images.csv\n",
      "c:\\Users\\ASUS\\Documents\\Python Programming\\Book recommendations\\Data\\Processed\\popular_books_with_descriptions.csv\n",
      "c:\\Users\\ASUS\\Documents\\Python Programming\\Book recommendations\\Data\\Processed\\ratings_for_popular_books.csv\n",
      "c:\\Users\\ASUS\\Documents\\Python Programming\\Book recommendations\\Data\\Processed\\Ratings_valid_ISBN.csv\n",
      "c:\\Users\\ASUS\\Documents\\Python Programming\\Book recommendations\\Data\\Processed\\users_valid_age_with_country.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data is contained in '../Data/Processed' directory\n",
    "# This cell lists all files under the input directory\n",
    "\n",
    "import os\n",
    "INPUT_DIR = os.path.join(os.path.dirname(os.getcwd()), 'Data', 'Processed')\n",
    "for dirname, _, filenames in os.walk(INPUT_DIR):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a4576",
   "metadata": {
    "papermill": {
     "duration": 0.006457,
     "end_time": "2022-10-21T10:13:46.324604",
     "exception": false,
     "start_time": "2022-10-21T10:13:46.318147",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us try to find similarities between books using their descriptions. We will use TF-IDF metric which stand for \"term frequence inverse document frequency\" and is computed by the following formula: \n",
    "$$TF-IDF=\\frac{\\frac{\\text{# word occurrences}}{\\text{# words in document}}}{\\log\\left(\\frac{\\text{# documents word is in}}{\\text{# documents}}\\right)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e3e371",
   "metadata": {
    "papermill": {
     "duration": 0.006018,
     "end_time": "2022-10-21T10:13:46.337209",
     "exception": false,
     "start_time": "2022-10-21T10:13:46.331191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We first load the information about the books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e752bad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:46.352168Z",
     "iopub.status.busy": "2022-10-21T10:13:46.351706Z",
     "iopub.status.idle": "2022-10-21T10:13:46.406104Z",
     "shell.execute_reply": "2022-10-21T10:13:46.404900Z"
    },
    "papermill": {
     "duration": 0.064541,
     "end_time": "2022-10-21T10:13:46.408375",
     "exception": false,
     "start_time": "2022-10-21T10:13:46.343834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94 entries, 0 to 93\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Unnamed: 0   94 non-null     int64 \n",
      " 1   title        94 non-null     object\n",
      " 2   authors      94 non-null     object\n",
      " 3   description  94 non-null     object\n",
      " 4   ISBN         94 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.8+ KB\n",
      "None\n",
      "   Unnamed: 0                                             title  \\\n",
      "0           0                                       Wild Animus   \n",
      "1           1                                  The Lovely Bones   \n",
      "2           2                                 The Da Vinci Code   \n",
      "3           3  Divine secrets of the Ya-Ya Sisterhood : a novel   \n",
      "4           4                                      The Red Tent   \n",
      "\n",
      "             authors                                        description  \\\n",
      "0   ['Rich Shapero']  Wild animus is a search for the primordial, a ...   \n",
      "1   ['Alice Sebold']  The spirit of fourteen-year-old Susie Salmon d...   \n",
      "2      ['Dan Brown']  Harvard symbologist Robert Langdon and French ...   \n",
      "3  ['Rebecca Wells']  A NOVEL ABOUT THE COMPLEX BONDS BETWEEN A MOTH...   \n",
      "4  ['Anita Diamant']  Her name is Dinah. In the Bible, her life is o...   \n",
      "\n",
      "         ISBN  \n",
      "0  0971880107  \n",
      "1  0316666343  \n",
      "2  0385504209  \n",
      "3  0060928336  \n",
      "4  0312195516  \n"
     ]
    }
   ],
   "source": [
    "books_df = pd.read_csv(os.path.join(INPUT_DIR, 'popular_books_with_descriptions.csv'))\n",
    "print(books_df.info())\n",
    "print(books_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149f1c3",
   "metadata": {
    "papermill": {
     "duration": 0.006016,
     "end_time": "2022-10-21T10:13:46.420786",
     "exception": false,
     "start_time": "2022-10-21T10:13:46.414770",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We import TfidfVectorizer and initialize it so that we only look for words that occur at least twice in our descriptions (unique words won't help us with similarity) and no more than in 75% of the descriptions (so that we ignore words like 'the', 'a', 'for' and so on). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc49426c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:46.437089Z",
     "iopub.status.busy": "2022-10-21T10:13:46.435833Z",
     "iopub.status.idle": "2022-10-21T10:13:47.701376Z",
     "shell.execute_reply": "2022-10-21T10:13:47.700234Z"
    },
    "papermill": {
     "duration": 1.27781,
     "end_time": "2022-10-21T10:13:47.704729",
     "exception": false,
     "start_time": "2022-10-21T10:13:46.426919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfvec = TfidfVectorizer(min_df=2, max_df=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0ee72a",
   "metadata": {
    "papermill": {
     "duration": 0.006274,
     "end_time": "2022-10-21T10:13:47.718862",
     "exception": false,
     "start_time": "2022-10-21T10:13:47.712588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we fit our TfidfVectorizer to the descriptions of books and extract the words (features) with the measures for every description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e674da2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:47.733773Z",
     "iopub.status.busy": "2022-10-21T10:13:47.733064Z",
     "iopub.status.idle": "2022-10-21T10:13:47.766634Z",
     "shell.execute_reply": "2022-10-21T10:13:47.765625Z"
    },
    "papermill": {
     "duration": 0.046001,
     "end_time": "2022-10-21T10:13:47.771252",
     "exception": false,
     "start_time": "2022-10-21T10:13:47.725251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '100' '2003' '50' 'about' 'accident' 'acclaimed' 'account'\n",
      " 'accused' 'achievement' 'adult' 'adventure' 'affair' 'after' 'again'\n",
      " 'against' 'age' 'agent' 'alice' 'alive' 'all' 'alone' 'along' 'also'\n",
      " 'american' 'an' 'ancient' 'angeles' 'any' 'anyone' 'are' 'around' 'array'\n",
      " 'as' 'assistant' 'at' 'attempts' 'attorney' 'aunt' 'author' 'avenue'\n",
      " 'award' 'away' 'baby' 'back' 'bank' 'baptist' 'be' 'beautiful' 'became'\n",
      " 'because' 'become' 'becomes' 'been' 'before' 'begins' 'behavior' 'behind'\n",
      " 'being' 'believe' 'beloved' 'best' 'bestseller' 'bestselling' 'betrayal'\n",
      " 'between' 'beyond' 'biggest' 'black' 'blend' 'blood' 'bonds' 'book'\n",
      " 'books' 'both' 'boy' 'boyfriend' 'boys' 'brazil' 'breaking' 'brief'\n",
      " 'bright' 'brilliant' 'brings' 'brother' 'brought' 'brutally' 'but' 'buy'\n",
      " 'by' 'california' 'called' 'calling' 'came' 'can' 'captures' 'car' 'care'\n",
      " 'caring' 'carolina' 'case' 'celebrate' 'centuries' 'century' 'changed'\n",
      " 'changes' 'characters' 'chicago' 'child' 'childhood' 'children'\n",
      " 'chilling' 'chinese' 'chronicle' 'chronicles' 'citizens' 'city' 'claire'\n",
      " 'class' 'classic' 'closer' 'club' 'coast' 'cold' 'colin' 'college' 'come'\n",
      " 'comes' 'comfort' 'comical' 'coming' 'community' 'company' 'complete'\n",
      " 'complex' 'confessions' 'conflict' 'confronts' 'congo' 'convinced' 'cost'\n",
      " 'could' 'country' 'courage' 'covered' 'created' 'creates' 'creation'\n",
      " 'creature' 'crime' 'cultural' 'culture' 'dangerous' 'dangers' 'dark'\n",
      " 'darkness' 'daughter' 'daughters' 'david' 'day' 'days' 'death' 'deaths'\n",
      " 'deep' 'deeply' 'demons' 'descends' 'describes' 'destiny' 'detective'\n",
      " 'devastatingly' 'did' 'died' 'different' 'disappearing' 'disastrous'\n",
      " 'discover' 'discovered' 'discovers' 'disillusioned' 'disturbing' 'doesn'\n",
      " 'dolores' 'don' 'down' 'drama' 'during' 'dying' 'each' 'earlier' 'early'\n",
      " 'eccentric' 'efforts' 'eight' 'elderly' 'else' 'embark' 'embarks' 'emma'\n",
      " 'emotional' 'emotions' 'encounter' 'end' 'entertainment' 'epic' 'escape'\n",
      " 'even' 'ever' 'everlasting' 'every' 'everything' 'everywhere' 'evil' 'ex'\n",
      " 'expedition' 'experience' 'extraordinary' 'eyes' 'face' 'faces' 'faith'\n",
      " 'fall' 'falls' 'family' 'fantasy' 'far' 'farm' 'father' 'fbi' 'fears'\n",
      " 'feel' 'female' 'few' 'fiction' 'fifteen' 'film' 'finally' 'find' 'finds'\n",
      " 'finger' 'firm' 'first' 'firth' 'fishing' 'five' 'food' 'for' 'forbidden'\n",
      " 'forces' 'forever' 'form' 'former' 'found' 'four' 'francisco' 'free'\n",
      " 'french' 'friend' 'friends' 'friendship' 'frightening' 'from' 'front'\n",
      " 'full' 'funny' 'future' 'generations' 'get' 'giant' 'giddy' 'gifts'\n",
      " 'girl' 'girls' 'give' 'glamorous' 'goes' 'going' 'gold' 'good' 'got'\n",
      " 'grace' 'great' 'greatest' 'grief' 'group' 'grown' 'had' 'hailed' 'hand'\n",
      " 'happened' 'happens' 'happy' 'hard' 'harrowing' 'harvard' 'has' 'have'\n",
      " 'having' 'he' 'healing' 'health' 'heart' 'heartache' 'heartbreaking'\n",
      " 'hearted' 'heaven' 'help' 'her' 'here' 'hero' 'heroine' 'herself'\n",
      " 'hidden' 'high' 'hilarious' 'him' 'himself' 'his' 'history' 'hogwarts'\n",
      " 'hold' 'holds' 'home' 'homicide' 'honor' 'hope' 'how' 'human' 'humor'\n",
      " 'hundred' 'husband' 'if' 'ii' 'in' 'including' 'independent' 'injured'\n",
      " 'inside' 'inspiration' 'intense' 'into' 'introduces' 'irish' 'is'\n",
      " 'issues' 'it' 'its' 'james' 'japanese' 'job' 'john' 'joins' 'journalist'\n",
      " 'journey' 'joy' 'juggle' 'jury' 'just' 'keep' 'keeps' 'kill' 'killed'\n",
      " 'killer' 'kills' 'kind' 'know' 'known' 'knows' 'land' 'langdon' 'last'\n",
      " 'late' 'later' 'laughter' 'law' 'lawyer' 'leads' 'learn' 'learned'\n",
      " 'learns' 'leaving' 'lee' 'less' 'letter' 'life' 'lifelong' 'light' 'like'\n",
      " 'literature' 'little' 'live' 'lives' 'living' 'local' 'london' 'long'\n",
      " 'longings' 'look' 'los' 'lost' 'love' 'lover' 'made' 'magazine' 'magic'\n",
      " 'make' 'makes' 'man' 'manicured' 'marriage' 'married' 'matter' 'may' 'me'\n",
      " 'meet' 'member' 'memphis' 'men' 'meryl' 'mesmerizing' 'michael' 'middle'\n",
      " 'miles' 'million' 'millions' 'miss' 'missing' 'mississippi' 'mob'\n",
      " 'mockingbird' 'modern' 'moment' 'moore' 'more' 'most' 'mother'\n",
      " 'mountains' 'moved' 'moves' 'movie' 'moving' 'mr' 'mrs' 'much' 'murder'\n",
      " 'murdered' 'must' 'my' 'mysterious' 'mystery' 'name' 'named' 'nanny'\n",
      " 'national' 'near' 'needs' 'neighborhood' 'neighbors' 'never' 'new'\n",
      " 'newsweek' 'next' 'nicholas' 'night' 'no' 'north' 'not' 'notable'\n",
      " 'notebook' 'nothing' 'notions' 'novel' 'now' 'nyu' 'odyssey' 'off'\n",
      " 'office' 'often' 'old' 'on' 'once' 'one' 'only' 'oprah' 'or' 'order'\n",
      " 'ordinary' 'original' 'other' 'others' 'our' 'out' 'outside' 'over' 'own'\n",
      " 'pain' 'paperback' 'parents' 'park' 'party' 'pass' 'past' 'patrick' 'pbs'\n",
      " 'peace' 'peaceful' 'people' 'perfect' 'perhaps' 'period' 'person'\n",
      " 'personal' 'picture' 'piece' 'place' 'places' 'plane' 'playing' 'poet'\n",
      " 'police' 'popular' 'position' 'possible' 'post' 'power' 'praise'\n",
      " 'precious' 'price' 'printing' 'prison' 'prize' 'production' 'profoundly'\n",
      " 'proves' 'pulitzer' 'quest' 'rare' 'read' 'reader' 'readers' 'reads'\n",
      " 'really' 'recent' 'recounting' 'red' 'redeeming' 'regarded' 'reissue'\n",
      " 'relationship' 'relationships' 'releasing' 'relentless' 'remarkable'\n",
      " 'remember' 'reprint' 'responsible' 'return' 'returns' 'reveals' 'review'\n",
      " 'rich' 'robert' 'roots' 'rumors' 'run' 'running' 'same' 'san' 'save'\n",
      " 'school' 'scientist' 'sea' 'search' 'secret' 'secrets' 'secure'\n",
      " 'seductive' 'seeking' 'selection' 'self' 'sensitive' 'sent' 'serial'\n",
      " 'series' 'set' 'sets' 'seven' 'sex' 'share' 'she' 'sister' 'sisters'\n",
      " 'slowly' 'small' 'so' 'socialite' 'society' 'some' 'someone' 'something'\n",
      " 'sometimes' 'son' 'sons' 'soon' 'sophie' 'source' 'south' 'southern'\n",
      " 'sparks' 'special' 'spirit' 'spring' 'star' 'starring' 'stories' 'storm'\n",
      " 'story' 'strange' 'streep' 'strength' 'struggles' 'struggling' 'student'\n",
      " 'stunning' 'summer' 'summoned' 'surprising' 'suspicious' 'sweet'\n",
      " 'sweetheart' 'symbologist' 'take' 'taken' 'takes' 'tale' 'talented'\n",
      " 'tapestry' 'target' 'tasks' 'tears' 'technology' 'tells' 'ten' 'tend'\n",
      " 'terms' 'terrain' 'terrible' 'terrifying' 'testament' 'than' 'that'\n",
      " 'their' 'them' 'themselves' 'then' 'there' 'these' 'they' 'thirty' 'this'\n",
      " 'those' 'thought' 'threatens' 'three' 'thriller' 'thrilling' 'through'\n",
      " 'thus' 'tie' 'time' 'timeless' 'times' 'title' 'to' 'today' 'together'\n",
      " 'told' 'too' 'top' 'touch' 'touched' 'towards' 'town' 'track'\n",
      " 'traditions' 'tragedy' 'tragic' 'trapped' 'trial' 'trouble' 'true'\n",
      " 'truth' 'turn' 'turns' 'twenty' 'two' 'ultimately' 'under' 'underground'\n",
      " 'understand' 'unexpected' 'unforgettable' 'unimaginable' 'universal'\n",
      " 'unlikely' 'until' 'up' 'upon' 'us' 'usa' 'use' 'using' 'utterly'\n",
      " 'vampire' 'vast' 'victim' 'victims' 'violence' 'violent' 'vivid' 'voice'\n",
      " 'wants' 'war' 'was' 'washington' 'waters' 'way' 'we' 'week' 'weekly'\n",
      " 'well' 'were' 'what' 'when' 'where' 'which' 'while' 'white' 'who' 'whose'\n",
      " 'why' 'wife' 'wild' 'will' 'winner' 'winning' 'wisdom' 'witchcraft'\n",
      " 'with' 'wizardry' 'woman' 'womanhood' 'women' 'won' 'work' 'working'\n",
      " 'works' 'world' 'worse' 'worth' 'writer' 'writing' 'ya' 'year' 'years'\n",
      " 'yet' 'york' 'you' 'young' 'your']\n"
     ]
    }
   ],
   "source": [
    "descriptions_vectorized = tfidfvec.fit_transform(books_df['description'])\n",
    "features = tfidfvec.get_feature_names_out()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4917e11",
   "metadata": {
    "papermill": {
     "duration": 0.006356,
     "end_time": "2022-10-21T10:13:47.784953",
     "exception": false,
     "start_time": "2022-10-21T10:13:47.778597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we create a dataframe with books as index and features as columns, where the tfidf is contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d35dc67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:47.800738Z",
     "iopub.status.busy": "2022-10-21T10:13:47.800079Z",
     "iopub.status.idle": "2022-10-21T10:13:47.868169Z",
     "shell.execute_reply": "2022-10-21T10:13:47.866348Z"
    },
    "papermill": {
     "duration": 0.080264,
     "end_time": "2022-10-21T10:13:47.872333",
     "exception": false,
     "start_time": "2022-10-21T10:13:47.792069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 94 entries, 0971880107 to 014028009X\n",
      "Columns: 770 entries, 000 to your\n",
      "dtypes: float64(770)\n",
      "memory usage: 566.2+ KB\n",
      "None\n",
      "                 000  100  2003        50     about  accident  acclaimed  \\\n",
      "ISBN                                                                       \n",
      "0971880107  0.000000  0.0   0.0  0.000000  0.000000       0.0        0.0   \n",
      "0316666343  0.187292  0.0   0.0  0.200221  0.000000       0.0        0.0   \n",
      "0385504209  0.000000  0.0   0.0  0.000000  0.000000       0.0        0.0   \n",
      "0060928336  0.000000  0.0   0.0  0.000000  0.269716       0.0        0.0   \n",
      "0312195516  0.000000  0.0   0.0  0.000000  0.078475       0.0        0.0   \n",
      "\n",
      "            account  accused  achievement  ...  writer  writing   ya  \\\n",
      "ISBN                                       ...                         \n",
      "0971880107      0.0      0.0     0.000000  ...     0.0      0.0  0.0   \n",
      "0316666343      0.0      0.0     0.000000  ...     0.0      0.0  0.0   \n",
      "0385504209      0.0      0.0     0.000000  ...     0.0      0.0  0.0   \n",
      "0060928336      0.0      0.0     0.000000  ...     0.0      0.0  0.0   \n",
      "0312195516      0.0      0.0     0.136672  ...     0.0      0.0  0.0   \n",
      "\n",
      "                year  years  yet  york  you  young  your  \n",
      "ISBN                                                      \n",
      "0971880107  0.000000    0.0  0.0   0.0  0.0    0.0   0.0  \n",
      "0316666343  0.130993    0.0  0.0   0.0  0.0    0.0   0.0  \n",
      "0385504209  0.000000    0.0  0.0   0.0  0.0    0.0   0.0  \n",
      "0060928336  0.000000    0.0  0.0   0.0  0.0    0.0   0.0  \n",
      "0312195516  0.000000    0.0  0.0   0.0  0.0    0.0   0.0  \n",
      "\n",
      "[5 rows x 770 columns]\n"
     ]
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(descriptions_vectorized.toarray(), columns=features, index = books_df['ISBN'])\n",
    "print(tfidf_df.info())\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096b18c3",
   "metadata": {
    "papermill": {
     "duration": 0.009751,
     "end_time": "2022-10-21T10:13:47.890212",
     "exception": false,
     "start_time": "2022-10-21T10:13:47.880461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we will use cosine similarity to measure how close books are to each other, that is, we will compute cosine between all pairs of vectors that we created for our books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42827de8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:47.912441Z",
     "iopub.status.busy": "2022-10-21T10:13:47.911676Z",
     "iopub.status.idle": "2022-10-21T10:13:47.997669Z",
     "shell.execute_reply": "2022-10-21T10:13:47.995544Z"
    },
    "papermill": {
     "duration": 0.100174,
     "end_time": "2022-10-21T10:13:48.002146",
     "exception": false,
     "start_time": "2022-10-21T10:13:47.901972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.03359607 0.0213571  ... 0.0927257  0.03033521 0.07000027]\n",
      " [0.03359607 1.         0.09032357 ... 0.13652754 0.08103767 0.0898522 ]\n",
      " [0.0213571  0.09032357 1.         ... 0.02379762 0.01113739 0.02934729]\n",
      " ...\n",
      " [0.0927257  0.13652754 0.02379762 ... 1.         0.10624941 0.16409527]\n",
      " [0.03033521 0.08103767 0.01113739 ... 0.10624941 1.         0.12142527]\n",
      " [0.07000027 0.0898522  0.02934729 ... 0.16409527 0.12142527 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity_array = cosine_similarity(tfidf_df)\n",
    "print(cosine_similarity_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3625433c",
   "metadata": {
    "papermill": {
     "duration": 0.007023,
     "end_time": "2022-10-21T10:13:48.017057",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.010034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So, we got out table with pairwise cosine similarities. On the diagonal we have 1s as we should, since that is similarity between the book and itself. Let us find the largest similarity that is not 1 and check what pair of books is that similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "735c5445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:48.034303Z",
     "iopub.status.busy": "2022-10-21T10:13:48.032954Z",
     "iopub.status.idle": "2022-10-21T10:13:48.044424Z",
     "shell.execute_reply": "2022-10-21T10:13:48.042724Z"
    },
    "papermill": {
     "duration": 0.02262,
     "end_time": "2022-10-21T10:13:48.047121",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.024501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 55) 0.9484526538675051\n",
      "Unnamed: 0                                                    21\n",
      "title                                          The Nanny Diaries\n",
      "authors                      ['Emma Mclaughlin', 'Nicola Kraus']\n",
      "description    A satirical glimpse into Manhattan's upper cla...\n",
      "ISBN                                                  0312278586\n",
      "Name: 21, dtype: object\n",
      "Unnamed: 0                                                    55\n",
      "title                                          The Nanny Diaries\n",
      "authors                      ['Emma McLaughlin', 'Nicola Kraus']\n",
      "description    Nanny, a struggling NYU student, takes a posit...\n",
      "ISBN                                                  0312291639\n",
      "Name: 55, dtype: object\n"
     ]
    }
   ],
   "source": [
    "no_diagonal = cosine_similarity_array.copy()\n",
    "np.fill_diagonal(no_diagonal, 0)\n",
    "#print(cosine_similarity_array)\n",
    "#print(no_diagonal)\n",
    "ind = np.unravel_index(np.argmax(no_diagonal, axis=None), no_diagonal.shape)\n",
    "print(ind, no_diagonal[ind])\n",
    "print(books_df.iloc[ind[0]])\n",
    "print(books_df.iloc[ind[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21829a",
   "metadata": {
    "papermill": {
     "duration": 0.00681,
     "end_time": "2022-10-21T10:13:48.060953",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.054143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Unsurprisingly, the two most similar books in our list are what seems to be the different instances of the same book. It is unclear why there are two different ISBNs for this book but indeed there are two different pages on Amazon, one published in 2002 and the other in 2003."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e954d60",
   "metadata": {
    "papermill": {
     "duration": 0.006887,
     "end_time": "2022-10-21T10:13:48.075123",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.068236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us try to find Harry Potter books and see if they are similar to each other by our metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a758cf66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:48.090479Z",
     "iopub.status.busy": "2022-10-21T10:13:48.090092Z",
     "iopub.status.idle": "2022-10-21T10:13:48.100206Z",
     "shell.execute_reply": "2022-10-21T10:13:48.099002Z"
    },
    "papermill": {
     "duration": 0.021815,
     "end_time": "2022-10-21T10:13:48.103824",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.082009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0                                      title            authors  \\\n",
      "10          10      Harry Potter and the Sorcerer's Stone  ['J. K. Rowling']   \n",
      "64          64  Harry Potter and the Order of the Phoenix  ['J. K. Rowling']   \n",
      "\n",
      "                                          description        ISBN  \n",
      "10  Rescued from the outrageous neglect of his aun...  059035342X  \n",
      "64  Collects the complete series that relates the ...  043935806X  \n"
     ]
    }
   ],
   "source": [
    "harry_potter_books_df = books_df[books_df['title'].str.contains('Harry Potter')]\n",
    "print(harry_potter_books_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7117498",
   "metadata": {
    "papermill": {
     "duration": 0.007002,
     "end_time": "2022-10-21T10:13:48.117819",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.110817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So, we have two Harry Potter books in our dataset. Let us check what their similarity is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0689127d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:48.133560Z",
     "iopub.status.busy": "2022-10-21T10:13:48.133058Z",
     "iopub.status.idle": "2022-10-21T10:13:48.139079Z",
     "shell.execute_reply": "2022-10-21T10:13:48.137850Z"
    },
    "papermill": {
     "duration": 0.016807,
     "end_time": "2022-10-21T10:13:48.141513",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.124706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41135157773840547\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity_array[(10, 64)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a68bc8",
   "metadata": {
    "papermill": {
     "duration": 0.006596,
     "end_time": "2022-10-21T10:13:48.155107",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.148511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "They seem to be quite similar!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75814037",
   "metadata": {
    "papermill": {
     "duration": 0.006527,
     "end_time": "2022-10-21T10:13:48.168504",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.161977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now it is time to create user profiles. For each user, we will recommend something they haven't read yet but what is similar to what they have read and like (that is, gave a rating of at least 7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b98f8d",
   "metadata": {
    "papermill": {
     "duration": 0.007121,
     "end_time": "2022-10-21T10:13:48.182676",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.175555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us create a list of users that gave a rating of at least 7 to at least one book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6854b555",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:48.199381Z",
     "iopub.status.busy": "2022-10-21T10:13:48.198988Z",
     "iopub.status.idle": "2022-10-21T10:13:48.270705Z",
     "shell.execute_reply": "2022-10-21T10:13:48.268978Z"
    },
    "papermill": {
     "duration": 0.084081,
     "end_time": "2022-10-21T10:13:48.274262",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.190181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17737 entries, 0 to 17736\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Unnamed: 0   17737 non-null  int64 \n",
      " 1   User-ID      17737 non-null  int64 \n",
      " 2   ISBN         17737 non-null  object\n",
      " 3   Book-Rating  17737 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 554.4+ KB\n",
      "None\n",
      "   Unnamed: 0  User-ID        ISBN  Book-Rating\n",
      "0          80   276788  043935806X            7\n",
      "1         414   276925  0385504209            8\n",
      "2         624   276953  0446310786           10\n",
      "3         665   276964  0440220602            9\n",
      "4         785   277042  0971880107            2\n"
     ]
    }
   ],
   "source": [
    "ratings_df = pd.read_csv(os.path.join(INPUT_DIR, 'ratings_for_popular_books.csv'))\n",
    "print(ratings_df.info())\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39331d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:48.291686Z",
     "iopub.status.busy": "2022-10-21T10:13:48.290411Z",
     "iopub.status.idle": "2022-10-21T10:13:48.310598Z",
     "shell.execute_reply": "2022-10-21T10:13:48.308860Z"
    },
    "papermill": {
     "duration": 0.031604,
     "end_time": "2022-10-21T10:13:48.313602",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.281998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-ID\n",
      "26        1\n",
      "51        1\n",
      "91        1\n",
      "114       1\n",
      "165       1\n",
      "         ..\n",
      "278698    1\n",
      "278773    1\n",
      "278798    1\n",
      "278843    3\n",
      "278844    1\n",
      "Length: 8760, dtype: int64\n",
      "Int64Index([    26,     51,     91,    114,    165,    243,    244,    254,\n",
      "               256,    280,\n",
      "            ...\n",
      "            278535, 278541, 278552, 278582, 278633, 278698, 278773, 278798,\n",
      "            278843, 278844],\n",
      "           dtype='int64', name='User-ID', length=8760)\n"
     ]
    }
   ],
   "source": [
    "print(ratings_df[ratings_df['Book-Rating'] >= 7].groupby('User-ID').size())\n",
    "users = ratings_df[ratings_df['Book-Rating'] >= 7].groupby('User-ID').size().index\n",
    "print(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20851df0",
   "metadata": {
    "papermill": {
     "duration": 0.00668,
     "end_time": "2022-10-21T10:13:48.327565",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.320885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we will take a random user and try to recommend some books for that user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c50e262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:48.344282Z",
     "iopub.status.busy": "2022-10-21T10:13:48.343098Z",
     "iopub.status.idle": "2022-10-21T10:13:48.350667Z",
     "shell.execute_reply": "2022-10-21T10:13:48.348588Z"
    },
    "papermill": {
     "duration": 0.018846,
     "end_time": "2022-10-21T10:13:48.353507",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.334661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231264\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "user_0 = users[np.random.randint(len(users))]\n",
    "print(user_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09dab2be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:48.369723Z",
     "iopub.status.busy": "2022-10-21T10:13:48.369259Z",
     "iopub.status.idle": "2022-10-21T10:13:48.380020Z",
     "shell.execute_reply": "2022-10-21T10:13:48.378358Z"
    },
    "papermill": {
     "duration": 0.021643,
     "end_time": "2022-10-21T10:13:48.382486",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.360843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0                                             title  \\\n",
      "ISBN                                                                       \n",
      "0971880107           0                                       Wild Animus   \n",
      "0316666343           1                                  The Lovely Bones   \n",
      "0385504209           2                                 The Da Vinci Code   \n",
      "0060928336           3  Divine secrets of the Ya-Ya Sisterhood : a novel   \n",
      "0312195516           4                                      The Red Tent   \n",
      "\n",
      "                      authors  \\\n",
      "ISBN                            \n",
      "0971880107   ['Rich Shapero']   \n",
      "0316666343   ['Alice Sebold']   \n",
      "0385504209      ['Dan Brown']   \n",
      "0060928336  ['Rebecca Wells']   \n",
      "0312195516  ['Anita Diamant']   \n",
      "\n",
      "                                                  description  \n",
      "ISBN                                                           \n",
      "0971880107  Wild animus is a search for the primordial, a ...  \n",
      "0316666343  The spirit of fourteen-year-old Susie Salmon d...  \n",
      "0385504209  Harvard symbologist Robert Langdon and French ...  \n",
      "0060928336  A NOVEL ABOUT THE COMPLEX BONDS BETWEEN A MOTH...  \n",
      "0312195516  Her name is Dinah. In the Bible, her life is o...  \n"
     ]
    }
   ],
   "source": [
    "books_by_isbn_df = books_df.set_index('ISBN')\n",
    "print(books_by_isbn_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8a7dd9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-21T10:13:48.399304Z",
     "iopub.status.busy": "2022-10-21T10:13:48.398875Z",
     "iopub.status.idle": "2022-10-21T10:13:48.440422Z",
     "shell.execute_reply": "2022-10-21T10:13:48.438874Z"
    },
    "papermill": {
     "duration": 0.055076,
     "end_time": "2022-10-21T10:13:48.445163",
     "exception": false,
     "start_time": "2022-10-21T10:13:48.390087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The books the user has liked:\n",
      "            Unnamed: 0                                  title  \\\n",
      "ISBN                                                            \n",
      "014028009X          93                  Bridget Jones's Diary   \n",
      "0142000205          90                             Icy Sparks   \n",
      "059035342X          10  Harry Potter and the Sorcerer's Stone   \n",
      "\n",
      "                         authors  \\\n",
      "ISBN                               \n",
      "014028009X    ['Helen Fielding']   \n",
      "0142000205  ['Gwyn Hyman Rubio']   \n",
      "059035342X     ['J. K. Rowling']   \n",
      "\n",
      "                                                  description  \n",
      "ISBN                                                           \n",
      "014028009X  USA Today's top 100 books to read while stuck ...  \n",
      "0142000205  A New York Times Notable Book and the March 20...  \n",
      "059035342X  Rescued from the outrageous neglect of his aun...  \n",
      "            similarity score                        title\n",
      "ISBN                                                     \n",
      "0385335482          0.379123  Confessions of a Shopaholic\n",
      "0446606812          0.319479          Message in a Bottle\n",
      "0446364193          0.314688          Along Came a Spider\n",
      "0316601950          0.293191             The Pilot's Wife\n",
      "0440226430          0.290313               Summer Sisters\n",
      "...                      ...                          ...\n",
      "044021145X          0.034805                     The Firm\n",
      "067976402X          0.031135       Snow Falling on Cedars\n",
      "0679781587          0.020876          Memoirs of a Geisha\n",
      "0804106304          0.019657            The Joy Luck Club\n",
      "0060938455          0.004664             Fast Food Nation\n",
      "\n",
      "[91 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def recommendations_for_user(user):\n",
    "    user_ratings_df = ratings_df[ratings_df['User-ID'] == user]\n",
    "    books_read = user_ratings_df['ISBN']\n",
    "    books_liked = user_ratings_df['ISBN'][user_ratings_df['Book-Rating'] >= 7]\n",
    "    user_books_tfidf = tfidf_df.reindex(books_liked)\n",
    "    user_profile = user_books_tfidf.mean()\n",
    "    print(\"The books the user has liked:\")\n",
    "    print(books_by_isbn_df.loc[books_liked])\n",
    "#    print(user_books_tfidf)\n",
    "#    print(user_profile)\n",
    "    unread_books_tfidf = tfidf_df.drop(books_read, axis=0)\n",
    "    user_profile_similarities = cosine_similarity(user_profile.values.reshape(1,-1), unread_books_tfidf)\n",
    "    user_profile_similarities_df = pd.DataFrame(user_profile_similarities.T, index=unread_books_tfidf.index, \\\n",
    "                                                columns=[\"similarity score\"])\n",
    "    sorted_similarities_df = user_profile_similarities_df.sort_values(by=\"similarity score\", ascending=False)\n",
    "    sorted_similarities_df['title'] = books_by_isbn_df['title'][sorted_similarities_df.index]\n",
    "    print(sorted_similarities_df)\n",
    "    \n",
    "recommendations_for_user(278843)    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.254023,
   "end_time": "2022-10-21T10:13:51.398249",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-21T10:13:37.144226",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
